# Lost and Found Streamlit Application

This is a Streamlit-based application that allows users to report lost items, search for lost items, and resolve cases. The application uses Google Cloud Storage (GCS) to store images of lost items and MySQL for database storage. It utilizes OpenAI's CLIP model to find matching items based on either text descriptions or images.

## Features

- **Report a Lost Item**: Users can upload an image or take a picture of their lost item and provide information about the campus and building where the item was lost.
- **Find a Lost Item**: Users can search for lost items either by text description or by uploading an image.
- **Resolve Cases (Staff Only)**: Staff can mark lost items as resolved and provide owner details for retrieval.
- **User Authentication**: Admin users can access and resolve lost items through a login system.
- **Database Management**: The application automatically creates and manages a MySQL database for storing lost items, resolved items, users, and locations.

## Prerequisites

Before running the application, make sure you have the following:

- Python 3.x
- Streamlit
- Google Cloud Storage (GCS) bucket
- MySQL database setup
- Required Python libraries installed

### Required Libraries

To install the required libraries, run the following command:

```bash
pip install -r requirements.txt
```

# Streamlit Interface
The app has three main options in the interface:

1. Report a Lost Item:
Users can either upload an image of a lost item or take a picture using the camera. They are also required to select the campus and building where the item was lost. The image is then uploaded to Google Cloud Storage, and a record is created in the MySQL database.

2. Find a Lost Item:
Users can search for lost items either by providing a text description or by uploading an image of the lost item. The application uses CLIP model embeddings to compare the query with existing lost items and returns the best match.

3. Resolve Cases (Staff Only):
Staff can log in with their credentials and resolve lost items. They can mark items as found and provide the owner's details.

# Models Used
The app uses the CLIP model from OpenAI to compare image and text descriptions and find matching lost items. It uses embeddings generated by the model to calculate similarity scores between the query and the stored items.

# Database Models
The application uses the following database tables to manage data:

- **LostItems**: Stores records of lost items, including image name, location, timestamp, embedding, and status.
- **ResolvedItems**: Stores records of items that have been found, including owner details.
- **Users**: Stores user information, including usernames, password hashes, and admin status.
- **Locations**: Stores campus, building, and contact email information for lost and found locations.
